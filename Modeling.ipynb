{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>marker</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>title_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Elizabeth Warren is Officially Leading the 202...</td>\n",
       "      <td>D</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Joe Biden: Trump won’t destroy me, and he won’...</td>\n",
       "      <td>D</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.8750</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Tucker Carlson attacks the awful Shep Smith, a...</td>\n",
       "      <td>R</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.7096</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>How California is using the courts to fight th...</td>\n",
       "      <td>D</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Adam Schiff has 2 aides who worked with whistl...</td>\n",
       "      <td>R</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles marker    neg    neu  \\\n",
       "0  Elizabeth Warren is Officially Leading the 202...      D  0.000  1.000   \n",
       "1  Joe Biden: Trump won’t destroy me, and he won’...      D  0.196  0.804   \n",
       "2  Tucker Carlson attacks the awful Shep Smith, a...      R  0.312  0.688   \n",
       "3  How California is using the courts to fight th...      D  0.181  0.819   \n",
       "4  Adam Schiff has 2 aides who worked with whistl...      R  0.000  1.000   \n",
       "\n",
       "   pos  compound  title_length  \n",
       "0  0.0    0.0000            53  \n",
       "1  0.0   -0.8750           261  \n",
       "2  0.0   -0.7096           104  \n",
       "3  0.0   -0.4939           144  \n",
       "4  0.0    0.0000            68  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics_reddit=pd.read_csv('politics_reddit.csv',index_col='Unnamed: 0')\n",
    "politics_reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split and check for balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=politics_reddit['titles']\n",
    "y=politics_reddit['marker'].map(lambda x: 1 if x=='R' else 0)\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    624\n",
       "1    314\n",
       "Name: marker, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts() #1 is outbalanced by 2 to 1 leading to stratification of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3347547974413646"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean() #baseline score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((703,), (703,), (235,), (235,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model instantiation and scoring, uses a mixture of unregularized and gridsearching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Accuracy Score:0.9601706970128022\n",
      "Best Training Accuracy Score:0.6978723404255319\n"
     ]
    }
   ],
   "source": [
    "cv_lr_pipe=Pipeline([\n",
    "    ( 'cv', CountVectorizer()),\n",
    "    ('lr',LogisticRegressionCV())\n",
    "])\n",
    "\n",
    "cv_lr_pipe.fit(X_train,y_train)\n",
    "print(f'Best Training Accuracy Score:{cv_lr_pipe.score(X_train,y_train)}')\n",
    "print(f'Best Training Accuracy Score:{cv_lr_pipe.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'cv__ngram_range': (1, 3), 'cv__stop_words': None, 'lr__Cs': array([10.])}\n",
      "Best Training Accuracy Score:0.7140825035561877\n",
      "Best Test Accuracy Score:0.7319148936170212\n"
     ]
    }
   ],
   "source": [
    "params_cv_lr={\n",
    "    'cv__stop_words':[None,'english'],\n",
    "    'cv__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "    'lr__Cs':[np.logspace(1,10,1)]}\n",
    "\n",
    "gs_cv_lr=GridSearchCV(cv_lr_pipe,\n",
    "                     params_cv_lr,\n",
    "                     cv=3)\n",
    "gs_cv_lr.fit(X_train,y_train)\n",
    "print(f'Best params:{gs_cv_lr.best_params_}')\n",
    "print(f'Best Training Accuracy Score:{gs_cv_lr.best_score_}')\n",
    "print(f'Best Test Accuracy Score:{gs_cv_lr.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Accuracy Score:1.0\n",
      "Best Training Accuracy Score:0.7191489361702128\n"
     ]
    }
   ],
   "source": [
    "tf_lr_pipe=Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('lr',LogisticRegressionCV())\n",
    "])\n",
    "\n",
    "tf_lr_pipe.fit(X_train,y_train)\n",
    "print(f'Best Training Accuracy Score:{tf_lr_pipe.score(X_train,y_train)}')\n",
    "print(f'Best Training Accuracy Score:{tf_lr_pipe.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'lr__Cs': array([10.]), 'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}\n",
      "Best Training Accuracy Score:0.6913229018492176\n",
      "Best Test Accuracy Score:0.7021276595744681\n"
     ]
    }
   ],
   "source": [
    "params_tf_lr={\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "    'lr__Cs':[np.logspace(1,10,1)]}\n",
    "\n",
    "gs_tf_lr=GridSearchCV(tf_lr_pipe,\n",
    "                     params_tf_lr,\n",
    "                     cv=3)\n",
    "\n",
    "gs_tf_lr.fit(X_train,y_train)\n",
    "print(f'Best params:{gs_tf_lr.best_params_}')\n",
    "print(f'Best Training Accuracy Score:{gs_tf_lr.best_score_}')\n",
    "print(f'Best Test Accuracy Score:{gs_tf_lr.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Accuracy Score:0.9260312944523471\n",
      "Best Training Accuracy Score:0.6808510638297872\n"
     ]
    }
   ],
   "source": [
    "cv_mbn_pipe=Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('mbn',MultinomialNB())\n",
    "])\n",
    "cv_mbn_pipe.fit(X_train,y_train)\n",
    "print(f'Best Training Accuracy Score:{cv_mbn_pipe.score(X_train,y_train)}')\n",
    "print(f'Best Training Accuracy Score:{cv_mbn_pipe.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'cv__ngram_range': (1, 2), 'cv__stop_words': None}\n",
      "Best Training Accuracy Score:0.6799431009957326\n",
      "Best Test Accuracy Score:0.6680851063829787\n"
     ]
    }
   ],
   "source": [
    "params_cv={\n",
    "    'cv__stop_words':[None,'english'],\n",
    "    'cv__ngram_range':[(1,1),(1,2),(1,3)]}\n",
    "\n",
    "gs_cv_mbn=GridSearchCV(cv_mbn_pipe,\n",
    "                     params_cv,\n",
    "                     cv=3)\n",
    "\n",
    "gs_cv_mbn.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best params:{gs_cv_mbn.best_params_}')\n",
    "print(f'Best Training Accuracy Score:{gs_cv_mbn.best_score_}')\n",
    "print(f'Best Test Accuracy Score:{gs_cv_mbn.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Accuracy Score:0.7795163584637269\n",
      "Best Training Accuracy Score:0.6680851063829787\n"
     ]
    }
   ],
   "source": [
    "tf_mbn_pipe=Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('mbn',MultinomialNB())\n",
    "])\n",
    "\n",
    "tf_mbn_pipe.fit(X_train,y_train)\n",
    "print(f'Best Training Accuracy Score:{tf_mbn_pipe.score(X_train,y_train)}')\n",
    "print(f'Best Training Accuracy Score:{tf_mbn_pipe.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "Best Training Accuracy Score:0.6770981507823614\n",
      "Best Test Accuracy Score:0.6723404255319149\n"
     ]
    }
   ],
   "source": [
    "params_tf={\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__ngram_range':[(1,1),(1,2),(1,3)]}\n",
    "\n",
    "gs_tf_mbn=GridSearchCV(tf_mbn_pipe,\n",
    "                     params_tf,\n",
    "                     cv=3)\n",
    "gs_tf_mbn.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best params:{gs_tf_mbn.best_params_}')\n",
    "print(f'Best Training Accuracy Score:{gs_tf_mbn.best_score_}')\n",
    "print(f'Best Test Accuracy Score:{gs_tf_mbn.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Accuracy Score:0.9359886201991465\n",
      "Best Training Accuracy Score:0.6851063829787234\n"
     ]
    }
   ],
   "source": [
    "cv_bnb_pipe=Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('bnb',BernoulliNB())\n",
    "])\n",
    "\n",
    "cv_bnb_pipe.fit(X_train,y_train)\n",
    "print(f'Best Training Accuracy Score:{cv_bnb_pipe.score(X_train,y_train)}')\n",
    "print(f'Best Training Accuracy Score:{cv_bnb_pipe.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'cv__ngram_range': (1, 1), 'cv__stop_words': None}\n",
      "Best Training Accuracy Score:0.6742532005689901\n",
      "Best Test Accuracy Score:0.6851063829787234\n"
     ]
    }
   ],
   "source": [
    "params_cv={\n",
    "    'cv__stop_words':[None,'english'],\n",
    "    'cv__ngram_range':[(1,1),(1,2),(1,3)]}\n",
    "\n",
    "gs_cv_bnb=GridSearchCV(cv_bnb_pipe,\n",
    "                     params_cv,\n",
    "                     cv=3)\n",
    "\n",
    "gs_cv_bnb.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best params:{gs_cv_bnb.best_params_}')\n",
    "print(f'Best Training Accuracy Score:{gs_cv_bnb.best_score_}')\n",
    "print(f'Best Test Accuracy Score:{gs_cv_bnb.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Accuracy Score:0.9359886201991465\n",
      "Best Training Accuracy Score:0.6851063829787234\n"
     ]
    }
   ],
   "source": [
    "tf_bnb_pipe=Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('bnb',BernoulliNB())])\n",
    "\n",
    "tf_bnb_pipe.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best Training Accuracy Score:{tf_bnb_pipe.score(X_train,y_train)}')\n",
    "print(f'Best Training Accuracy Score:{tf_bnb_pipe.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'tf__ngram_range': (1, 1), 'tf__stop_words': None}\n",
      "Best Training Accuracy Score:0.6742532005689901\n",
      "Best Test Accuracy Score:0.6851063829787234\n"
     ]
    }
   ],
   "source": [
    "params_tf={\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__ngram_range':[(1,1),(1,2),(1,3)]}\n",
    "\n",
    "\n",
    "gs_tf_bnb=GridSearchCV(tf_bnb_pipe,\n",
    "                     params_tf,\n",
    "                     cv=3)\n",
    "\n",
    "gs_tf_bnb.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best params:{gs_tf_bnb.best_params_}')\n",
    "print(f'Best Training Accuracy Score:{gs_tf_bnb.best_score_}')\n",
    "print(f'Best Test Accuracy Score:{gs_tf_bnb.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Accuracy Score:0.6813655761024182\n",
      "Best Training Accuracy Score:0.4765957446808511\n"
     ]
    }
   ],
   "source": [
    "cv_knn_pipe=Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('knn',KNeighborsClassifier())])\n",
    "\n",
    "cv_knn_pipe.fit(X_train,y_train)\n",
    "print(f'Best Training Accuracy Score:{cv_knn_pipe.score(X_train,y_train)}')\n",
    "print(f'Best Training Accuracy Score:{cv_knn_pipe.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english', 'knn__n_neighbors': 3, 'knn__p': 2}\n",
      "Best Training Accuracy Score:0.5419630156472262\n",
      "Best Test Accuracy Score:0.5957446808510638\n"
     ]
    }
   ],
   "source": [
    "params_cv_knn={\n",
    "    'cv__stop_words':[None,'english'],\n",
    "    'cv__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "    'knn__n_neighbors':[3,5,7,9,15],\n",
    "    'knn__p':[1,2]}\n",
    "\n",
    "gs_cv_knn=GridSearchCV(cv_knn_pipe,\n",
    "                     params_cv_knn,\n",
    "                     cv=3)\n",
    "\n",
    "gs_cv_knn.fit(X_train,y_train)\n",
    "print(f'Best params:{gs_cv_knn.best_params_}')\n",
    "print(f'Best Training Accuracy Score:{gs_cv_knn.best_score_}')\n",
    "print(f'Best Test Accuracy Score:{gs_cv_knn.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Accuracy Score:0.7695590327169275\n",
      "Best Training Accuracy Score:0.676595744680851\n"
     ]
    }
   ],
   "source": [
    "tf_knn_pipe=Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('knn',KNeighborsClassifier())])\n",
    "\n",
    "tf_knn_pipe.fit(X_train,y_train)\n",
    "print(f'Best Training Accuracy Score:{tf_knn_pipe.score(X_train,y_train)}')\n",
    "print(f'Best Training Accuracy Score:{tf_knn_pipe.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'knn__n_neighbors': 9, 'knn__p': 2, 'tf__ngram_range': (1, 1), 'tf__stop_words': None}\n",
      "Best Training Accuracy Score:0.6785206258890469\n",
      "Best Test Accuracy Score:0.6595744680851063\n"
     ]
    }
   ],
   "source": [
    "params_tf_knn={\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "    'knn__n_neighbors':[3,5,7,9,15],\n",
    "    'knn__p':[1,2]}\n",
    "\n",
    "gs_tf_knn=GridSearchCV(tf_knn_pipe,\n",
    "                     params_tf_knn,\n",
    "                     cv=3)\n",
    "\n",
    "gs_tf_knn.fit(X_train,y_train)\n",
    "print(f'Best params:{gs_tf_knn.best_params_}')\n",
    "print(f'Best Training Accuracy Score:{gs_tf_knn.best_score_}')\n",
    "print(f'Best Test Accuracy Score:{gs_tf_knn.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather words and coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_lr_pipe.named_steps['cv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=cv_lr_pipe.named_steps['cv'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_lr_coef=cv_lr_pipe.named_steps['lr'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zuckerberg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3382"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf_lr_pipe.named_steps['tf'].get_feature_names()[-1])\n",
    "len(tf_lr_pipe.named_steps['tf'].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_lr_coef=tf_lr_pipe.named_steps['lr'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mbn_coef=cv_mbn_pipe.named_steps['mbn'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_mbn_coef=tf_mbn_pipe.named_steps['mbn'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_mbn_coef=tf_mbn_pipe.named_steps['mbn'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_bnb_coef=cv_bnb_pipe.named_steps['bnb'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_bnb_coef=tf_bnb_pipe.named_steps['bnb'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe for further modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df=pd.DataFrame({'words':words,\n",
    "                      'cv_lr_coef':cv_lr_coef,\n",
    "                      'tf_lr_coef':tf_lr_coef,\n",
    "                      'cv_mbn_coef':cv_mbn_coef,\n",
    "                      'tf_mbn_coef':tf_mbn_coef,\n",
    "                      'cv_bnb_coef':cv_bnb_coef,\n",
    "                      'tf_bnb_coef':tf_bnb_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>cv_lr_coef</th>\n",
       "      <th>tf_lr_coef</th>\n",
       "      <th>cv_mbn_coef</th>\n",
       "      <th>tf_mbn_coef</th>\n",
       "      <th>cv_bnb_coef</th>\n",
       "      <th>tf_bnb_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>-0.138481</td>\n",
       "      <td>-1.090025</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>09</td>\n",
       "      <td>-0.043993</td>\n",
       "      <td>-0.406573</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.098460</td>\n",
       "      <td>-0.668320</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.048649</td>\n",
       "      <td>-0.329723</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-8.119376</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10m</td>\n",
       "      <td>-0.056806</td>\n",
       "      <td>-0.280052</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.179016</td>\n",
       "      <td>-1.202437</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>11th</td>\n",
       "      <td>-0.014776</td>\n",
       "      <td>-0.206866</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.037105</td>\n",
       "      <td>-0.105699</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-8.122278</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>120</td>\n",
       "      <td>-0.006599</td>\n",
       "      <td>-0.178084</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.164234</td>\n",
       "      <td>-1.111443</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0.056027</td>\n",
       "      <td>0.542083</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-8.021409</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>-0.002447</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-8.134447</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.066146</td>\n",
       "      <td>-0.646721</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>0.154715</td>\n",
       "      <td>1.183424</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-8.020478</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.092456</td>\n",
       "      <td>0.891584</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-8.006634</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1994</td>\n",
       "      <td>-0.019722</td>\n",
       "      <td>-0.304464</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.183657</td>\n",
       "      <td>0.841169</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-8.171468</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.083610</td>\n",
       "      <td>0.376942</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-8.177828</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19th</td>\n",
       "      <td>-0.015813</td>\n",
       "      <td>-0.262122</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.102161</td>\n",
       "      <td>-0.670124</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   words  cv_lr_coef  tf_lr_coef  cv_mbn_coef  tf_mbn_coef  cv_bnb_coef  \\\n",
       "0    000   -0.138481   -1.090025    -8.737292    -8.324987    -5.468060   \n",
       "1     09   -0.043993   -0.406573    -8.737292    -8.324987    -5.468060   \n",
       "2     10   -0.098460   -0.668320    -8.737292    -8.324987    -5.468060   \n",
       "3    100   -0.048649   -0.329723    -8.044145    -8.119376    -4.774913   \n",
       "4    10m   -0.056806   -0.280052    -8.737292    -8.324987    -5.468060   \n",
       "5     11   -0.179016   -1.202437    -8.737292    -8.324987    -5.468060   \n",
       "6   11th   -0.014776   -0.206866    -8.737292    -8.324987    -5.468060   \n",
       "7     12    0.037105   -0.105699    -8.044145    -8.122278    -4.774913   \n",
       "8    120   -0.006599   -0.178084    -8.737292    -8.324987    -5.468060   \n",
       "9     13   -0.164234   -1.111443    -8.737292    -8.324987    -5.468060   \n",
       "10    14    0.056027    0.542083    -8.044145    -8.021409    -4.774913   \n",
       "11    15    0.010338   -0.002447    -8.044145    -8.134447    -4.774913   \n",
       "12    16   -0.066146   -0.646721    -8.737292    -8.324987    -5.468060   \n",
       "13    17    0.154715    1.183424    -8.044145    -8.020478    -4.774913   \n",
       "14  1992    0.092456    0.891584    -8.044145    -8.006634    -4.774913   \n",
       "15  1994   -0.019722   -0.304464    -8.737292    -8.324987    -5.468060   \n",
       "16  1998    0.183657    0.841169    -8.044145    -8.171468    -4.774913   \n",
       "17  1999    0.083610    0.376942    -8.044145    -8.177828    -4.774913   \n",
       "18  19th   -0.015813   -0.262122    -8.737292    -8.324987    -5.468060   \n",
       "19    20   -0.102161   -0.670124    -8.737292    -8.324987    -5.468060   \n",
       "\n",
       "    tf_bnb_coef  \n",
       "0     -5.468060  \n",
       "1     -5.468060  \n",
       "2     -5.468060  \n",
       "3     -4.774913  \n",
       "4     -5.468060  \n",
       "5     -5.468060  \n",
       "6     -5.468060  \n",
       "7     -4.774913  \n",
       "8     -5.468060  \n",
       "9     -5.468060  \n",
       "10    -4.774913  \n",
       "11    -4.774913  \n",
       "12    -5.468060  \n",
       "13    -4.774913  \n",
       "14    -4.774913  \n",
       "15    -5.468060  \n",
       "16    -4.774913  \n",
       "17    -4.774913  \n",
       "18    -5.468060  \n",
       "19    -5.468060  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>cv_lr_coef</th>\n",
       "      <th>tf_lr_coef</th>\n",
       "      <th>cv_mbn_coef</th>\n",
       "      <th>tf_mbn_coef</th>\n",
       "      <th>cv_bnb_coef</th>\n",
       "      <th>tf_bnb_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3362</td>\n",
       "      <td>wrote</td>\n",
       "      <td>0.222833</td>\n",
       "      <td>2.057842</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-7.956542</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3363</td>\n",
       "      <td>wsj</td>\n",
       "      <td>-0.101946</td>\n",
       "      <td>-0.934357</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3364</td>\n",
       "      <td>wtmf</td>\n",
       "      <td>-0.019635</td>\n",
       "      <td>-0.310617</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3365</td>\n",
       "      <td>wwii</td>\n",
       "      <td>0.161972</td>\n",
       "      <td>1.566688</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-7.992260</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3366</td>\n",
       "      <td>yang</td>\n",
       "      <td>-0.309954</td>\n",
       "      <td>-2.591764</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3367</td>\n",
       "      <td>yascha</td>\n",
       "      <td>-0.002525</td>\n",
       "      <td>-0.102047</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3368</td>\n",
       "      <td>year</td>\n",
       "      <td>-0.086079</td>\n",
       "      <td>-0.529720</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-8.148265</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3369</td>\n",
       "      <td>years</td>\n",
       "      <td>-0.088446</td>\n",
       "      <td>-0.930100</td>\n",
       "      <td>-7.638680</td>\n",
       "      <td>-8.003708</td>\n",
       "      <td>-4.369448</td>\n",
       "      <td>-4.369448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3370</td>\n",
       "      <td>yes</td>\n",
       "      <td>-0.060752</td>\n",
       "      <td>-0.795286</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3371</td>\n",
       "      <td>yet</td>\n",
       "      <td>-0.122053</td>\n",
       "      <td>-1.065893</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3372</td>\n",
       "      <td>york</td>\n",
       "      <td>-0.172473</td>\n",
       "      <td>-1.377564</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3373</td>\n",
       "      <td>you</td>\n",
       "      <td>-0.349373</td>\n",
       "      <td>-2.052446</td>\n",
       "      <td>-6.945533</td>\n",
       "      <td>-7.553838</td>\n",
       "      <td>-3.676301</td>\n",
       "      <td>-3.676301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3374</td>\n",
       "      <td>young</td>\n",
       "      <td>-0.005882</td>\n",
       "      <td>-0.238879</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3375</td>\n",
       "      <td>your</td>\n",
       "      <td>-0.057837</td>\n",
       "      <td>0.131412</td>\n",
       "      <td>-7.127854</td>\n",
       "      <td>-7.598934</td>\n",
       "      <td>-3.858622</td>\n",
       "      <td>-3.858622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3376</td>\n",
       "      <td>yr</td>\n",
       "      <td>-0.035581</td>\n",
       "      <td>-0.354488</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3377</td>\n",
       "      <td>yuriy</td>\n",
       "      <td>-0.003679</td>\n",
       "      <td>-0.041648</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3378</td>\n",
       "      <td>zelenskiy</td>\n",
       "      <td>-0.066540</td>\n",
       "      <td>-0.581253</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3379</td>\n",
       "      <td>zelensky</td>\n",
       "      <td>-0.031352</td>\n",
       "      <td>-0.500247</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>zero</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.029517</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3381</td>\n",
       "      <td>zuckerberg</td>\n",
       "      <td>-0.042675</td>\n",
       "      <td>-0.249849</td>\n",
       "      <td>-7.638680</td>\n",
       "      <td>-7.854200</td>\n",
       "      <td>-4.369448</td>\n",
       "      <td>-4.369448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  cv_lr_coef  tf_lr_coef  cv_mbn_coef  tf_mbn_coef  \\\n",
       "3362       wrote    0.222833    2.057842    -8.044145    -7.956542   \n",
       "3363         wsj   -0.101946   -0.934357    -8.737292    -8.324987   \n",
       "3364        wtmf   -0.019635   -0.310617    -8.737292    -8.324987   \n",
       "3365        wwii    0.161972    1.566688    -8.044145    -7.992260   \n",
       "3366        yang   -0.309954   -2.591764    -8.737292    -8.324987   \n",
       "3367      yascha   -0.002525   -0.102047    -8.737292    -8.324987   \n",
       "3368        year   -0.086079   -0.529720    -8.044145    -8.148265   \n",
       "3369       years   -0.088446   -0.930100    -7.638680    -8.003708   \n",
       "3370         yes   -0.060752   -0.795286    -8.737292    -8.324987   \n",
       "3371         yet   -0.122053   -1.065893    -8.737292    -8.324987   \n",
       "3372        york   -0.172473   -1.377564    -8.737292    -8.324987   \n",
       "3373         you   -0.349373   -2.052446    -6.945533    -7.553838   \n",
       "3374       young   -0.005882   -0.238879    -8.737292    -8.324987   \n",
       "3375        your   -0.057837    0.131412    -7.127854    -7.598934   \n",
       "3376          yr   -0.035581   -0.354488    -8.737292    -8.324987   \n",
       "3377       yuriy   -0.003679   -0.041648    -8.737292    -8.324987   \n",
       "3378   zelenskiy   -0.066540   -0.581253    -8.737292    -8.324987   \n",
       "3379    zelensky   -0.031352   -0.500247    -8.737292    -8.324987   \n",
       "3380        zero   -0.000282   -0.029517    -8.737292    -8.324987   \n",
       "3381  zuckerberg   -0.042675   -0.249849    -7.638680    -7.854200   \n",
       "\n",
       "      cv_bnb_coef  tf_bnb_coef  \n",
       "3362    -4.774913    -4.774913  \n",
       "3363    -5.468060    -5.468060  \n",
       "3364    -5.468060    -5.468060  \n",
       "3365    -4.774913    -4.774913  \n",
       "3366    -5.468060    -5.468060  \n",
       "3367    -5.468060    -5.468060  \n",
       "3368    -4.774913    -4.774913  \n",
       "3369    -4.369448    -4.369448  \n",
       "3370    -5.468060    -5.468060  \n",
       "3371    -5.468060    -5.468060  \n",
       "3372    -5.468060    -5.468060  \n",
       "3373    -3.676301    -3.676301  \n",
       "3374    -5.468060    -5.468060  \n",
       "3375    -3.858622    -3.858622  \n",
       "3376    -5.468060    -5.468060  \n",
       "3377    -5.468060    -5.468060  \n",
       "3378    -5.468060    -5.468060  \n",
       "3379    -5.468060    -5.468060  \n",
       "3380    -5.468060    -5.468060  \n",
       "3381    -4.369448    -4.369448  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>cv_lr_coef</th>\n",
       "      <th>tf_lr_coef</th>\n",
       "      <th>cv_mbn_coef</th>\n",
       "      <th>tf_mbn_coef</th>\n",
       "      <th>cv_bnb_coef</th>\n",
       "      <th>tf_bnb_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3224</td>\n",
       "      <td>vision</td>\n",
       "      <td>-0.006599</td>\n",
       "      <td>-0.178084</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>bullet</td>\n",
       "      <td>0.066419</td>\n",
       "      <td>0.551390</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-8.075684</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2877</td>\n",
       "      <td>strength</td>\n",
       "      <td>-0.023880</td>\n",
       "      <td>-0.286258</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2737</td>\n",
       "      <td>shut</td>\n",
       "      <td>0.061488</td>\n",
       "      <td>0.639397</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-7.997804</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>body</td>\n",
       "      <td>-0.052449</td>\n",
       "      <td>-0.325377</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>amid</td>\n",
       "      <td>-0.001470</td>\n",
       "      <td>-0.109937</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>circle</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>-0.185875</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2317</td>\n",
       "      <td>principle</td>\n",
       "      <td>-0.001057</td>\n",
       "      <td>-0.156030</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>ago</td>\n",
       "      <td>0.096302</td>\n",
       "      <td>0.878572</td>\n",
       "      <td>-8.044145</td>\n",
       "      <td>-8.098112</td>\n",
       "      <td>-4.774913</td>\n",
       "      <td>-4.774913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1859</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>-0.072562</td>\n",
       "      <td>-0.652881</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2673</td>\n",
       "      <td>sellouts</td>\n",
       "      <td>-0.001057</td>\n",
       "      <td>-0.156030</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>caucus</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>-0.037046</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>blocking</td>\n",
       "      <td>-0.029464</td>\n",
       "      <td>-0.242388</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>holdouts</td>\n",
       "      <td>-0.047172</td>\n",
       "      <td>-0.449781</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2233</td>\n",
       "      <td>plans</td>\n",
       "      <td>-0.120443</td>\n",
       "      <td>-0.783818</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2199</td>\n",
       "      <td>percent</td>\n",
       "      <td>-0.071115</td>\n",
       "      <td>-0.699476</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2769</td>\n",
       "      <td>smith</td>\n",
       "      <td>-0.061299</td>\n",
       "      <td>-0.637099</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>armitage</td>\n",
       "      <td>-0.014776</td>\n",
       "      <td>-0.206866</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2324</td>\n",
       "      <td>probing</td>\n",
       "      <td>-0.126383</td>\n",
       "      <td>-1.088636</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>having</td>\n",
       "      <td>-0.203720</td>\n",
       "      <td>-1.622403</td>\n",
       "      <td>-8.737292</td>\n",
       "      <td>-8.324987</td>\n",
       "      <td>-5.468060</td>\n",
       "      <td>-5.468060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words  cv_lr_coef  tf_lr_coef  cv_mbn_coef  tf_mbn_coef  \\\n",
       "3224         vision   -0.006599   -0.178084    -8.737292    -8.324987   \n",
       "476          bullet    0.066419    0.551390    -8.044145    -8.075684   \n",
       "2877       strength   -0.023880   -0.286258    -8.737292    -8.324987   \n",
       "2737           shut    0.061488    0.639397    -8.044145    -7.997804   \n",
       "422            body   -0.052449   -0.325377    -8.737292    -8.324987   \n",
       "193            amid   -0.001470   -0.109937    -8.737292    -8.324987   \n",
       "584          circle   -0.003095   -0.185875    -8.737292    -8.324987   \n",
       "2317      principle   -0.001057   -0.156030    -8.737292    -8.324987   \n",
       "150             ago    0.096302    0.878572    -8.044145    -8.098112   \n",
       "1859  manufacturing   -0.072562   -0.652881    -8.737292    -8.324987   \n",
       "2673       sellouts   -0.001057   -0.156030    -8.737292    -8.324987   \n",
       "530          caucus   -0.001059   -0.037046    -8.737292    -8.324987   \n",
       "410        blocking   -0.029464   -0.242388    -8.737292    -8.324987   \n",
       "1450       holdouts   -0.047172   -0.449781    -8.737292    -8.324987   \n",
       "2233          plans   -0.120443   -0.783818    -8.737292    -8.324987   \n",
       "2199        percent   -0.071115   -0.699476    -8.737292    -8.324987   \n",
       "2769          smith   -0.061299   -0.637099    -8.737292    -8.324987   \n",
       "248        armitage   -0.014776   -0.206866    -8.737292    -8.324987   \n",
       "2324        probing   -0.126383   -1.088636    -8.737292    -8.324987   \n",
       "1400         having   -0.203720   -1.622403    -8.737292    -8.324987   \n",
       "\n",
       "      cv_bnb_coef  tf_bnb_coef  \n",
       "3224    -5.468060    -5.468060  \n",
       "476     -4.774913    -4.774913  \n",
       "2877    -5.468060    -5.468060  \n",
       "2737    -4.774913    -4.774913  \n",
       "422     -5.468060    -5.468060  \n",
       "193     -5.468060    -5.468060  \n",
       "584     -5.468060    -5.468060  \n",
       "2317    -5.468060    -5.468060  \n",
       "150     -4.774913    -4.774913  \n",
       "1859    -5.468060    -5.468060  \n",
       "2673    -5.468060    -5.468060  \n",
       "530     -5.468060    -5.468060  \n",
       "410     -5.468060    -5.468060  \n",
       "1450    -5.468060    -5.468060  \n",
       "2233    -5.468060    -5.468060  \n",
       "2199    -5.468060    -5.468060  \n",
       "2769    -5.468060    -5.468060  \n",
       "248     -5.468060    -5.468060  \n",
       "2324    -5.468060    -5.468060  \n",
       "1400    -5.468060    -5.468060  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.to_csv('words_coef.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix Using the optimized TF LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_best=gs_cv_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp=confusion_matrix(y_test,y_preds_best).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(tn, fp, fn, tp):\n",
    "    return np.sum([fp, fn])/np.sum([tn, fp, fn, tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(a, b, c, d):\n",
    "    return np.sum([d,a])/np.sum([a, b, c, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(a,b):\n",
    "    return b/np.sum([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(a,b):\n",
    "    return a/np.sum([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_positive(a,b):\n",
    "    return b/np.sum([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percession(a,b):\n",
    "    return b/np.sum([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 27, 36, 43)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2680851063829787"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7319148936170212"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45569620253164556"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(tp,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8269230769230769"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity(tn,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38571428571428573"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percession(tp,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8269230769230769"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive(fp,tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrases_df=pd.DataFrame({'test_words':X_test,\n",
    "                      'true_values':y_test,\n",
    "                      'pred_values':y_preds_best})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_words</th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>Trump gives green light to Turkey to attack.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>The Lights Are Out in California, And That Was the Plan All Along</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>David Frum on Twitter: \"Congress did not vote aid to Ukraine as an act of charity. Congress beli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>822</td>\n",
       "      <td>Committees Ready Subpoena for White House After Ukraine Documents Withheld for Weeks</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>927</td>\n",
       "      <td>Second whistleblower about Ukraine phone call coming forward. Uhm, dumbasses, we have the damn t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              test_words  \\\n",
       "400                                                         Trump gives green light to Turkey to attack.   \n",
       "136                                    The Lights Are Out in California, And That Was the Plan All Along   \n",
       "292  David Frum on Twitter: \"Congress did not vote aid to Ukraine as an act of charity. Congress beli...   \n",
       "822                 Committees Ready Subpoena for White House After Ukraine Documents Withheld for Weeks   \n",
       "927  Second whistleblower about Ukraine phone call coming forward. Uhm, dumbasses, we have the damn t...   \n",
       "\n",
       "     true_values  pred_values  \n",
       "400            0            1  \n",
       "136            1            0  \n",
       "292            0            0  \n",
       "822            0            0  \n",
       "927            1            0  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrases_df.reset_index(inplace=True)\n",
    "test_phrases_df.drop(columns='index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrases_df['good_preds'] = (test_phrases_df['true_values'] == test_phrases_df['pred_values']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_words</th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_values</th>\n",
       "      <th>good_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Trump gives green light to Turkey to attack.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The Lights Are Out in California, And That Was the Plan All Along</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Second whistleblower about Ukraine phone call coming forward. Uhm, dumbasses, we have the damn transcript.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Andrew McCabe Does an Interview and Makes a Stunning Admission</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Yang Gang Lights Up L.A.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>For anyone in Edinburgh, Scotland - the Jordan Peterson documentary is coming to a theatre near you!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>Biden’s Most Formidable Opponent Is Not Another Democrat - Questions about his age have dogged the former vice president throughout the primary.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>Mike Ghassali is running as a Republican for Congress in NJ-05. He is a legal immigrant from Syria, Mayor of Montvale, and a patriotic American! He has lowered taxes, and refused to make his town a “sanctuary city”. He has raised over 300k since July to unseat Josh Gottheimer. Let’s put NJ first!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>Just Remember: Roy Cohn Taught Him His ABCs”</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>GOP Congressional Leaders Demanding Answers on Hillary/Dems Soliciting Info From Ukraine During 2016 Election</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                    test_words  \\\n",
       "0                                                                                                                                                                                                                                                                 Trump gives green light to Turkey to attack.   \n",
       "1                                                                                                                                                                                                                                            The Lights Are Out in California, And That Was the Plan All Along   \n",
       "4                                                                                                                                                                                                   Second whistleblower about Ukraine phone call coming forward. Uhm, dumbasses, we have the damn transcript.   \n",
       "6                                                                                                                                                                                                                                               Andrew McCabe Does an Interview and Makes a Stunning Admission   \n",
       "8                                                                                                                                                                                                                                                                                     Yang Gang Lights Up L.A.   \n",
       "..                                                                                                                                                                                                                                                                                                         ...   \n",
       "217                                                                                                                                                                                                       For anyone in Edinburgh, Scotland - the Jordan Peterson documentary is coming to a theatre near you!   \n",
       "219                                                                                                                                                           Biden’s Most Formidable Opponent Is Not Another Democrat - Questions about his age have dogged the former vice president throughout the primary.   \n",
       "220  Mike Ghassali is running as a Republican for Congress in NJ-05. He is a legal immigrant from Syria, Mayor of Montvale, and a patriotic American! He has lowered taxes, and refused to make his town a “sanctuary city”. He has raised over 300k since July to unseat Josh Gottheimer. Let’s put NJ first!   \n",
       "231                                                                                                                                                                                                                                                               Just Remember: Roy Cohn Taught Him His ABCs”   \n",
       "232                                                                                                                                                                                              GOP Congressional Leaders Demanding Answers on Hillary/Dems Soliciting Info From Ukraine During 2016 Election   \n",
       "\n",
       "     true_values  pred_values  good_preds  \n",
       "0              0            1           0  \n",
       "1              1            0           0  \n",
       "4              1            0           0  \n",
       "6              1            0           0  \n",
       "8              0            1           0  \n",
       "..           ...          ...         ...  \n",
       "217            1            0           0  \n",
       "219            0            1           0  \n",
       "220            1            0           0  \n",
       "231            0            1           0  \n",
       "232            1            0           0  \n",
       "\n",
       "[63 rows x 4 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrases_df[test_phrases_df['good_preds']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrases_df.to_csv('test_phrase_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
